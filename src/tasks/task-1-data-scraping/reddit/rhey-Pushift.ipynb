{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pointed-motor",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* https://github.com/pushshift/api\n",
    "* https://search.pushshift.io/reddit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "innocent-shoot",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T10:13:50.395922Z",
     "start_time": "2021-07-04T10:13:46.333037Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gross-adaptation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T10:13:50.876959Z",
     "start_time": "2021-07-04T10:13:50.398053Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/spacy/util.py:709: UserWarning: [W095] Model 'en_core_web_sm' (2.3.1) requires spaCy >=2.3.0,<2.4.0 and is incompatible with the current version (3.0.6). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x159f8a250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)\n",
    "nlp.add_pipe('language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "first-packaging",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-04T10:13:54.691257Z",
     "start_time": "2021-07-04T10:13:50.879434Z"
    }
   },
   "outputs": [],
   "source": [
    "keyword = 'singapore%20mental%20health'\n",
    "\n",
    "data = requests.get('https://api.pushshift.io/reddit/submission/search/?q={}&sort=desc&sort_type=score&size=500'.format(keyword))\n",
    "information = json.loads(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-cutting",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-04T10:13:46.320Z"
    }
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for _information in information['data']:\n",
    "    subscribers = 0\n",
    "    subreddit_type = ''\n",
    "    author_premium = ''\n",
    "    total_awards_received = 0\n",
    "    upvote_ratio = 0\n",
    "    link_flair_text = ''\n",
    "    \n",
    "    if 'subreddit_subscribers' in _information.keys():\n",
    "        subscribers = _information['subreddit_subscribers']\n",
    "        \n",
    "    if 'subreddit_type' in _information.keys():\n",
    "        subreddit_type = _information['subreddit_type']\n",
    "        \n",
    "    if 'author_premium' in _information.keys():\n",
    "        author_premium = _information['author_premium']\n",
    "        \n",
    "    if 'total_awards_received' in _information.keys():\n",
    "        total_awards_received = _information['total_awards_received']\n",
    "        \n",
    "    if 'upvote_ratio' in _information.keys():\n",
    "        upvote_ratio = _information['upvote_ratio']\n",
    "        \n",
    "    if 'link_flair_text' in _information.keys():\n",
    "        link_flair_text = _information['link_flair_text']\n",
    "        \n",
    "    if 'selftext' in _information.keys():\n",
    "        selftext = _information['selftext']\n",
    "        \n",
    "\n",
    "    overall_content = _information['title']+\"\\n\\n\"+selftext\n",
    "    doc = nlp(overall_content)\n",
    "    language_details = doc._.language\n",
    "\n",
    "    result.append({\n",
    "      'post_id': _information['id'],\n",
    "      'subreddit_name':_information['subreddit'],\n",
    "      'subreddit_id':_information['subreddit_id'], \n",
    "      'subreddit_subscribers':subscribers,\n",
    "      'author':_information['author'], \n",
    "      'author_premium':author_premium,\n",
    "      'subreddit_type':subreddit_type, \n",
    "      'num_reports':0, \n",
    "      'title':_information['title'], \n",
    "      'body':selftext, \n",
    "      'overall_content':overall_content,   \n",
    "      'url':_information['url'],\n",
    "      'comments': _information['num_comments'],\n",
    "      'score': _information['score'], \n",
    "      'down_votes': 0,\n",
    "      'up_votes': 0,  \n",
    "      'upvote_ratio': upvote_ratio,  \n",
    "      'created_date': datetime.datetime.fromtimestamp(int(_information['created_utc'])).strftime('%c'), \n",
    "      'flair_text': link_flair_text,\n",
    "      'language': language_details['language'],\n",
    "      'language_score': language_details['score']\n",
    "    })\n",
    "\n",
    "posts_df = pd.DataFrame(\n",
    "    result,\n",
    ")\n",
    "\n",
    "display(posts_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
