{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e162a269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105223, 38)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "raw = pd.read_csv(\"raw-all-7-17-21.csv\")\n",
    "raw.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4507aeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'conversation_id', 'created_at', 'date', 'timezone',\n",
       "       'place', 'tweet', 'language', 'hashtags', 'cashtags', 'user_id',\n",
       "       'user_id_str', 'username', 'name', 'day', 'hour', 'link', 'urls',\n",
       "       'photos', 'video', 'thumbnail', 'retweet', 'nlikes', 'nreplies',\n",
       "       'nretweets', 'quote_url', 'search', 'near', 'geo', 'source',\n",
       "       'user_rt_id', 'user_rt', 'retweet_id', 'reply_to', 'retweet_date',\n",
       "       'translate', 'trans_src', 'trans_dest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c61bdaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98674, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove irrelevant features\n",
    "columns_keep = [ 'date', 'tweet', 'hashtags', 'username',\n",
    "                'nlikes', 'nreplies', 'nretweets', 'search', 'place', 'language']\n",
    "raw = raw[columns_keep]\n",
    "raw\n",
    "\n",
    "# Drop Irrelevant tweets by detecking keywords in tweets\n",
    "words = ['Johor', 'Malaysia', 'Sects', 'depression tribe', 'drkshdw', 'sects', 'valimai', 'myanmar']\n",
    "raw = raw[~raw.tweet.str.contains('|'.join(words))]\n",
    "\n",
    "# Drop Irrelevant tweets by detecking keywords in hashtags\n",
    "words = ['july6coup', 'dreadfulcovidamidmilitarycoup', 'whatshappeninginmyanmar', \n",
    "         'july3revilestrike', 'july6coup', 'whatshappeninginmyanmar', 'july4coup', \n",
    "         'june29coup', 'myanmar', 'june30coup', 'feb9coup', 'feb8coup', 'herethevoiceofmyanmar', \n",
    "         'savemyanmar', 'myanmarsnsfreedom', 'coup7feb', 'weneeddemocracy', 'fightfordemocracy', \n",
    "         \"againstmyanmarmilitarycoup\", \"ambarazahrah\"] \n",
    "raw = raw[~raw.hashtags.str.contains('|'.join(words))]\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1cc76c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78378, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "raw.drop_duplicates(inplace=True) \n",
    "raw.drop_duplicates(subset =\"tweet\", keep = False, inplace = True)\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d3271d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>nreplies</th>\n",
       "      <th>nretweets</th>\n",
       "      <th>search_keyword</th>\n",
       "      <th>lang</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-29 13:54:00</td>\n",
       "      <td>The best depression killer is worshipping Jesu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>JesusDailyTwits</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-29 12:47:00</td>\n",
       "      <td>I hope with the blessings of the majlis my dep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Aluvrendar</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-29 12:33:00</td>\n",
       "      <td>@kowey It feels like a theory of psychohistory...</td>\n",
       "      <td>[]</td>\n",
       "      <td>mengwong</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-28 18:33:00</td>\n",
       "      <td>Post Project Depression. Cant Believe That 12 ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>haziqqqaaahzik</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-12-26 02:16:00</td>\n",
       "      <td>Depression thought ????</td>\n",
       "      <td>[]</td>\n",
       "      <td>NASYRANN_</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105217</th>\n",
       "      <td>2021-01-28 07:44:00</td>\n",
       "      <td>STPI Honours Frontline Healthcare and Social W...</td>\n",
       "      <td>[]</td>\n",
       "      <td>russelwongphoto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>frontline</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105218</th>\n",
       "      <td>2021-01-26 15:02:00</td>\n",
       "      <td>Your Covid care speech drove us to be frontlin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>ShaheerBirdieFC</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>frontline</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105219</th>\n",
       "      <td>2021-01-23 12:41:00</td>\n",
       "      <td>I know it's still early days, but India seems ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>rishabhm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>frontline</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105220</th>\n",
       "      <td>2021-01-16 15:50:00</td>\n",
       "      <td>PM gets emotional while speaking about invalua...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Erongodath</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>frontline</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105222</th>\n",
       "      <td>2021-05-19 19:33:00</td>\n",
       "      <td>Like, is it super necessary for these people t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>MissFortuneCat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>school closure</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66893 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              tweet  \\\n",
       "1      2019-12-29 13:54:00  The best depression killer is worshipping Jesu...   \n",
       "2      2019-12-29 12:47:00  I hope with the blessings of the majlis my dep...   \n",
       "3      2019-12-29 12:33:00  @kowey It feels like a theory of psychohistory...   \n",
       "4      2019-12-28 18:33:00  Post Project Depression. Cant Believe That 12 ...   \n",
       "8      2019-12-26 02:16:00                            Depression thought ????   \n",
       "...                    ...                                                ...   \n",
       "105217 2021-01-28 07:44:00  STPI Honours Frontline Healthcare and Social W...   \n",
       "105218 2021-01-26 15:02:00  Your Covid care speech drove us to be frontlin...   \n",
       "105219 2021-01-23 12:41:00  I know it's still early days, but India seems ...   \n",
       "105220 2021-01-16 15:50:00  PM gets emotional while speaking about invalua...   \n",
       "105222 2021-05-19 19:33:00  Like, is it super necessary for these people t...   \n",
       "\n",
       "       hashtags         username  nlikes  nreplies  nretweets  search_keyword  \\\n",
       "1            []  JesusDailyTwits       1         0          0      depression   \n",
       "2            []       Aluvrendar      67         3          6      depression   \n",
       "3            []         mengwong       0         2          0      depression   \n",
       "4            []   haziqqqaaahzik      10         1          8      depression   \n",
       "8            []        NASYRANN_       0         1          3      depression   \n",
       "...         ...              ...     ...       ...        ...             ...   \n",
       "105217       []  russelwongphoto       0         0          0       frontline   \n",
       "105218       []  ShaheerBirdieFC       7         1          0       frontline   \n",
       "105219       []         rishabhm       0         0          0       frontline   \n",
       "105220       []       Erongodath       0         0          0       frontline   \n",
       "105222       []   MissFortuneCat       0         0          0  school closure   \n",
       "\n",
       "       lang  latitude  longitude  \n",
       "1        en       NaN        NaN  \n",
       "2        en       NaN        NaN  \n",
       "3        en       NaN        NaN  \n",
       "4        en       NaN        NaN  \n",
       "8        en       NaN        NaN  \n",
       "...     ...       ...        ...  \n",
       "105217   en       NaN        NaN  \n",
       "105218   en       NaN        NaN  \n",
       "105219   en       NaN        NaN  \n",
       "105220   en       NaN        NaN  \n",
       "105222   en       NaN        NaN  \n",
       "\n",
       "[66893 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(fp=raw):\n",
    "    df = fp\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df['latitude'] = df.place.map(lambda x:  eval(x)['coordinates'][0]\n",
    "                                  if not pd.isnull(x) else x)\n",
    "    df['longitude'] = df.place.map(lambda x:  eval(x)['coordinates'][1] \n",
    "                                   if not pd.isnull(x) else x)\n",
    "    df.drop('place', 1, inplace=True)\n",
    "    return (df.loc[df.language=='en']\n",
    "              .rename(columns=dict(language='lang', id='tweet_id',\n",
    "                                   search='search_keyword')))\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85040160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string \n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = list(get_stop_words('en'))\n",
    "nltk_words = list(stopwords.words('english'))\n",
    "stop_words.extend(nltk_words)\n",
    "from contraction_map import CONTRACTION_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6eff0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean thoroughly \n",
    "def remove_hyperlinks(text):\n",
    "    ptn = r'(https://[\\w./-]+)|(www.[\\w./-]+)|([\\w./-]+.com)'\n",
    "    return re.sub(ptn, '', text)\n",
    "\n",
    "def remove_mentions(text):\n",
    "    ptn = r'(@[\\w_]+ | (@[.]+) | (@))'\n",
    "    return re.sub(ptn, '', text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    #text = list(text)\n",
    "    text=' '.join([x for x in text.split() if x not in stop_words])\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text): \n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text) \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    #text = text.translate(None, string.punctuation)\n",
    "    return text \n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "    \n",
    "def remove_alphabets(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    return text \n",
    "\n",
    "def remove_digits(text):\n",
    "    text = ''.join(i for i in text if not i.isdigit())\n",
    "    return text\n",
    "\n",
    "def clean_text(text, hyperlink=True, mention=True, stopwords=True,\n",
    "               punctuations=True, contractions=True, digits=True,\n",
    "               lowercase=True, alphabets=True):\n",
    "    if lowercase: # Transform to lowercase\n",
    "        text = text.lower()\n",
    "    if hyperlink: # Remove Hyperlinks\n",
    "        text = remove_hyperlinks(text)\n",
    "    if mention: # Remove Mentions\n",
    "        text = remove_mentions(text)\n",
    "    if punctuations: # Remove Punctuations \n",
    "        text = remove_punctuations(text) \n",
    "    if contractions: # Expand Contractions e.g. can't -> cannot\n",
    "        text = expand_contractions(text)\n",
    "    if stopwords: # Remove english stopwords\n",
    "        text = remove_stopwords(text)\n",
    "    if alphabets: # Remove single alphabets \n",
    "        text = remove_alphabets(text)\n",
    "    if digits: # Remove all numbers\n",
    "        text = remove_digits(text)\n",
    "    return text\n",
    "\n",
    "raw['clean_tweet4'] = raw.tweet.map(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "416feb1f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>nreplies</th>\n",
       "      <th>nretweets</th>\n",
       "      <th>search</th>\n",
       "      <th>language</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>clean_tweet4</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-29 13:54:00</td>\n",
       "      <td>The best depression killer is worshipping Jesu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>JesusDailyTwits</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>best depression killer worshipping jesus try v...</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-29 12:47:00</td>\n",
       "      <td>I hope with the blessings of the majlis my dep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Aluvrendar</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hope blessings majlis depression never return ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-29 12:33:00</td>\n",
       "      <td>@kowey It feels like a theory of psychohistory...</td>\n",
       "      <td>[]</td>\n",
       "      <td>mengwong</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feels like theory psychohistory ing together h...</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-28 18:33:00</td>\n",
       "      <td>Post Project Depression. Cant Believe That 12 ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>haziqqqaaahzik</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>post project depression cant believe days ende...</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-12-26 02:16:00</td>\n",
       "      <td>Depression thought ????</td>\n",
       "      <td>[]</td>\n",
       "      <td>NASYRANN_</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>depression</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>depression thought</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105217</th>\n",
       "      <td>2021-01-28 07:44:00</td>\n",
       "      <td>STPI Honours Frontline Healthcare and Social W...</td>\n",
       "      <td>[]</td>\n",
       "      <td>russelwongphoto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>frontline</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stpi honours frontline healthcare social worke...</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105218</th>\n",
       "      <td>2021-01-26 15:02:00</td>\n",
       "      <td>Your Covid care speech drove us to be frontlin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>ShaheerBirdieFC</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>frontline</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>covid care speech drove us frontline warriors ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105219</th>\n",
       "      <td>2021-01-23 12:41:00</td>\n",
       "      <td>I know it's still early days, but India seems ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>rishabhm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>frontline</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>know still early days india seems administerin...</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105220</th>\n",
       "      <td>2021-01-16 15:50:00</td>\n",
       "      <td>PM gets emotional while speaking about invalua...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Erongodath</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>frontline</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pm gets emotional speaking invaluable contribu...</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105222</th>\n",
       "      <td>2021-05-19 19:33:00</td>\n",
       "      <td>Like, is it super necessary for these people t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>MissFortuneCat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>school closure</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>like super necessary people share things like ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66893 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              tweet  \\\n",
       "1      2019-12-29 13:54:00  The best depression killer is worshipping Jesu...   \n",
       "2      2019-12-29 12:47:00  I hope with the blessings of the majlis my dep...   \n",
       "3      2019-12-29 12:33:00  @kowey It feels like a theory of psychohistory...   \n",
       "4      2019-12-28 18:33:00  Post Project Depression. Cant Believe That 12 ...   \n",
       "8      2019-12-26 02:16:00                            Depression thought ????   \n",
       "...                    ...                                                ...   \n",
       "105217 2021-01-28 07:44:00  STPI Honours Frontline Healthcare and Social W...   \n",
       "105218 2021-01-26 15:02:00  Your Covid care speech drove us to be frontlin...   \n",
       "105219 2021-01-23 12:41:00  I know it's still early days, but India seems ...   \n",
       "105220 2021-01-16 15:50:00  PM gets emotional while speaking about invalua...   \n",
       "105222 2021-05-19 19:33:00  Like, is it super necessary for these people t...   \n",
       "\n",
       "       hashtags         username  nlikes  nreplies  nretweets          search  \\\n",
       "1            []  JesusDailyTwits       1         0          0      depression   \n",
       "2            []       Aluvrendar      67         3          6      depression   \n",
       "3            []         mengwong       0         2          0      depression   \n",
       "4            []   haziqqqaaahzik      10         1          8      depression   \n",
       "8            []        NASYRANN_       0         1          3      depression   \n",
       "...         ...              ...     ...       ...        ...             ...   \n",
       "105217       []  russelwongphoto       0         0          0       frontline   \n",
       "105218       []  ShaheerBirdieFC       7         1          0       frontline   \n",
       "105219       []         rishabhm       0         0          0       frontline   \n",
       "105220       []       Erongodath       0         0          0       frontline   \n",
       "105222       []   MissFortuneCat       0         0          0  school closure   \n",
       "\n",
       "       language  latitude  longitude  \\\n",
       "1            en       NaN        NaN   \n",
       "2            en       NaN        NaN   \n",
       "3            en       NaN        NaN   \n",
       "4            en       NaN        NaN   \n",
       "8            en       NaN        NaN   \n",
       "...         ...       ...        ...   \n",
       "105217       en       NaN        NaN   \n",
       "105218       en       NaN        NaN   \n",
       "105219       en       NaN        NaN   \n",
       "105220       en       NaN        NaN   \n",
       "105222       en       NaN        NaN   \n",
       "\n",
       "                                             clean_tweet4  year  month  \n",
       "1       best depression killer worshipping jesus try v...  2019     12  \n",
       "2       hope blessings majlis depression never return ...  2019     12  \n",
       "3       feels like theory psychohistory ing together h...  2019     12  \n",
       "4       post project depression cant believe days ende...  2019     12  \n",
       "8                                      depression thought  2019     12  \n",
       "...                                                   ...   ...    ...  \n",
       "105217  stpi honours frontline healthcare social worke...  2021      1  \n",
       "105218  covid care speech drove us frontline warriors ...  2021      1  \n",
       "105219  know still early days india seems administerin...  2021      1  \n",
       "105220  pm gets emotional speaking invaluable contribu...  2021      1  \n",
       "105222  like super necessary people share things like ...  2021      5  \n",
       "\n",
       "[66893 rows x 14 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = raw.loc[raw.language == \"en\"]\n",
    "\n",
    "raw[\"year\"] = raw[\"date\"].dt.year\n",
    "raw[\"month\"] = raw[\"date\"].dt.month\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84a7e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = raw.drop(labels=[\"latitude\", \"longitude\",\"language\", \"tweet\"], axis=1)\n",
    "clean_data.to_csv(\"final_clean_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5905fe9",
   "metadata": {},
   "source": [
    "# Lemmatizaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3831cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import nltk\n",
    "#nlp = spacy.load('en_core')\n",
    "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11df43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "clean_data[\"parse_tweet\"] = clean_data.clean_tweet4.map(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7525212",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_csv(\"final_lemmatized_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f54ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
