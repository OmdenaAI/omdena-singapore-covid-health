{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "# read in data\r\n",
                "import pandas as pd\r\n",
                "data = pd.read_csv(\"C:\\\\Users\\\\20jam\\\\Documents\\\\GitHub\\\\omdena-singapore-covid-health\\\\src\\\\data\\\\reddit\\\\final data files\\\\fulldata.csv\") # do this for full_data, midCOVID_data, preCOVID_data\r\n",
                "title = data.loc[:, \"title\"]\r\n",
                "body = data.loc[:, \"selftext\"]\r\n",
                "# comments = data.loc[:, \"comments\"]\r\n",
                "# print(title)\r\n",
                "# print(body)\r\n",
                "# print(comments)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# expand contractions\r\n",
                "import contractions\r\n",
                "expanded_title = []\r\n",
                "for text in title:\r\n",
                "    try:\r\n",
                "        expanded = []\r\n",
                "        for word in text.split():\r\n",
                "            expanded.append(contractions.fix(word))\r\n",
                "        expanded_text = \" \".join(expanded)\r\n",
                "        expanded_title.append(expanded_text)\r\n",
                "    except:\r\n",
                "        expanded_title.append(\"\")\r\n",
                "expanded_body = []\r\n",
                "for text in body:\r\n",
                "    try:\r\n",
                "        expanded = []\r\n",
                "        for word in text.split():\r\n",
                "            expanded.append(contractions.fix(word))\r\n",
                "        expanded_text = \" \".join(expanded)\r\n",
                "        expanded_body.append(expanded_text)\r\n",
                "    except:\r\n",
                "        expanded_body.append(\"\")\r\n",
                "\"\"\"\r\n",
                "comments column removed from db since it is not useful\r\n",
                "expanded_comments = []\r\n",
                "for text in comments:\r\n",
                "    try:\r\n",
                "        expanded = []\r\n",
                "        for word in text.split():\r\n",
                "            expanded.append(contractions.fix(word))\r\n",
                "        expanded_text = \" \".join(expanded)\r\n",
                "        expanded_comments.append(expanded_text)\r\n",
                "    except: # comments is NAN\r\n",
                "        expanded_comments.append(\"\")\r\n",
                "\"\"\""
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'\\ncomments column removed from db since it is not useful\\nexpanded_comments = []\\nfor text in comments:\\n    try:\\n        expanded = []\\n        for word in text.split():\\n            expanded.append(contractions.fix(word))\\n        expanded_text = \" \".join(expanded)\\n        expanded_comments.append(expanded_text)\\n    except: # comments is NAN\\n        expanded_comments.append(\"\")\\n'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 3
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# lower every case\r\n",
                "lower_title = [item.lower() for item in expanded_title]\r\n",
                "lower_body = [item.lower() for item in expanded_body]\r\n",
                "\"\"\"\r\n",
                "lower_comments = []\r\n",
                "for item in expanded_comments:\r\n",
                "    try:\r\n",
                "        lower_comments.append(item.lower())\r\n",
                "    except:\r\n",
                "        lower_comments.append(\"\")\r\n",
                "\"\"\""
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'\\nlower_comments = []\\nfor item in expanded_comments:\\n    try:\\n        lower_comments.append(item.lower())\\n    except:\\n        lower_comments.append(\"\")\\n'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "# remove stopwords\r\n",
                "import nltk\r\n",
                "from nltk.corpus import stopwords\r\n",
                "nltk.download(\"stopwords\")\r\n",
                "stop_words = set(stopwords.words(\"english\"))\r\n",
                "print(stop_words)\r\n",
                "\r\n",
                "stop_title = []\r\n",
                "for text in lower_title:\r\n",
                "    text = \" \".join([word for word in text.split() if word not in stop_words])\r\n",
                "    stop_title.append(text)\r\n",
                "stop_body = []\r\n",
                "for text in lower_body:\r\n",
                "    text = \" \".join([word for word in text.split() if word not in stop_words])\r\n",
                "    stop_body.append(text)\r\n",
                "\"\"\"\r\n",
                "stop_comments = []\r\n",
                "for text in lower_comments:\r\n",
                "    text = \" \".join([word for word in text.split() if word not in stop_words])\r\n",
                "    stop_comments.append(text)\r\n",
                "\"\"\""
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "[nltk_data] Downloading package stopwords to\n",
                        "[nltk_data]     C:\\Users\\20jam\\AppData\\Roaming\\nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{'they', 'should', 'most', \"wasn't\", \"shan't\", \"she's\", 'or', 'his', 'up', 'too', \"mightn't\", 'wasn', 'below', 'do', 'same', \"don't\", 'both', \"couldn't\", 'which', 'just', 'now', \"it's\", 'very', 'yourself', 'are', 'this', 'when', \"you'll\", 'she', 'other', 'be', 'until', 'my', 'shan', 'some', 'during', 'if', 'he', 'didn', 'hadn', 'what', 'to', 'couldn', \"hadn't\", 'been', 'nor', \"should've\", 'isn', 'shouldn', 'against', 'further', 'their', 'than', 'again', 'of', 'weren', 'in', 'over', 'needn', \"hasn't\", 'them', 'can', 't', 'haven', 'aren', 'won', 'more', 'an', 'your', 'from', 'having', 'these', 'it', 'does', \"won't\", 'has', 'the', 'theirs', 'doing', \"you'd\", 'on', 'don', 'such', 'have', 'for', 'ain', 'at', 'me', 'yourselves', 'mustn', 'did', 'down', 'any', \"isn't\", 'where', 'about', 'out', 'so', 'm', 'mightn', 'were', 'who', 'and', 'while', 'y', 'being', 's', 'only', 'a', 'hers', 'is', 'will', \"needn't\", 'our', 'her', 'because', 'after', \"haven't\", 'yours', 'herself', 'own', 'with', 'was', 'whom', 'each', 'myself', 'am', 'few', 'doesn', 'ma', 'had', \"weren't\", 'itself', 'not', \"that'll\", 'all', 'there', 'those', 'above', \"aren't\", 'ourselves', 'off', 'wouldn', 'once', \"you've\", 'that', 'i', 'into', 'under', 'hasn', 'you', 'we', 're', \"wouldn't\", 'themselves', 'as', 've', 'll', 'him', 'ours', 'before', 'its', 'then', 'himself', \"you're\", \"shouldn't\", 'through', 'why', \"didn't\", 'between', 'by', \"doesn't\", 'o', \"mustn't\", 'no', 'how', 'here', 'but', 'd'}\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'\\nstop_comments = []\\nfor text in lower_comments:\\n    text = \" \".join([word for word in text.split() if word not in stop_words])\\n    stop_comments.append(text)\\n'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 5
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "# repair broken unicode\r\n",
                "import ftfy\r\n",
                "ftfy_title = []\r\n",
                "for text in stop_title:\r\n",
                "    text = ftfy.fix_text(text)\r\n",
                "    ftfy_title.append(text)\r\n",
                "ftfy_body = []\r\n",
                "for text in stop_body:\r\n",
                "    text = ftfy.fix_text(text)\r\n",
                "    ftfy_body.append(text)\r\n",
                "\"\"\"\r\n",
                "ftfy_comments = []\r\n",
                "for text in stop_comments:\r\n",
                "    text = ftfy.fix_text(text)\r\n",
                "    ftfy_comments.append(text)\r\n",
                "\"\"\""
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'\\nftfy_comments = []\\nfor text in stop_comments:\\n    text = ftfy.fix_text(text)\\n    ftfy_comments.append(text)\\n'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 6
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# remove unicode\r\n",
                "import string\r\n",
                "unicode_title = []\r\n",
                "for text in ftfy_title:\r\n",
                "    text_encode = text.encode(encoding = \"ascii\", errors = \"ignore\")\r\n",
                "    text_decode = text_encode.decode()\r\n",
                "    clean_text = \" \".join([word for word in text_decode.split()]) # remove extra whitespace\r\n",
                "    unicode_title.append(clean_text)\r\n",
                "unicode_body = []\r\n",
                "for text in ftfy_body:\r\n",
                "    text_encode = text.encode(encoding = \"ascii\", errors = \"ignore\")\r\n",
                "    text_decode = text_encode.decode()\r\n",
                "    clean_text = \" \".join([word for word in text_decode.split()]) # remove extra whitespace\r\n",
                "    unicode_body.append(clean_text)\r\n",
                "\"\"\"\r\n",
                "unicode_comments = []\r\n",
                "for text in ftfy_comments:\r\n",
                "    text_encode = text.encode(encoding = \"ascii\", errors = \"ignore\")\r\n",
                "    text_decode = text_encode.decode()\r\n",
                "    clean_text = \" \".join([word for word in text_decode.split()]) # remove extra whitespace\r\n",
                "    unicode_comments.append(clean_text)\r\n",
                "\"\"\""
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'\\nunicode_comments = []\\nfor text in ftfy_comments:\\n    text_encode = text.encode(encoding = \"ascii\", errors = \"ignore\")\\n    text_decode = text_encode.decode()\\n    clean_text = \" \".join([word for word in text_decode.split()]) # remove extra whitespace\\n    unicode_comments.append(clean_text)\\n'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 7
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "# remove mentions, money sign, url, hashtags, punctuations, digits\r\n",
                "import re\r\n",
                "import string\r\n",
                "punct = set(string.punctuation)\r\n",
                "\r\n",
                "remove_title = []\r\n",
                "for text in unicode_title:\r\n",
                "    text = re.sub(\"@\\S+\", \"\", text)\r\n",
                "    text = re.sub(\"\\$\", \"\", text)\r\n",
                "    text = re.sub(r'http\\S+', \"\", text)\r\n",
                "    text = re.sub(\"#\", \"\", text)\r\n",
                "    text = \"\".join([ch for ch in text if ch not in punct])\r\n",
                "    text = re.sub(r'[0-9]', \"\", text)\r\n",
                "    remove_title.append(text)\r\n",
                "remove_body = []\r\n",
                "for text in unicode_body:\r\n",
                "    text = re.sub(\"@\\S+\", \"\", text)\r\n",
                "    text = re.sub(\"\\$\", \"\", text)\r\n",
                "    text = re.sub(r'http\\S+', \"\", text)\r\n",
                "    text = re.sub(\"#\", \"\", text)\r\n",
                "    text = \"\".join([ch for ch in text if ch not in punct])\r\n",
                "    text = re.sub(r'[0-9]', \"\", text)\r\n",
                "    remove_body.append(text)\r\n",
                "\"\"\"\r\n",
                "remove_comments = []\r\n",
                "for text in unicode_comments:\r\n",
                "    text = re.sub(\"@\\S+\", \"\", text)\r\n",
                "    text = re.sub(\"\\$\", \"\", text)\r\n",
                "    text = re.sub(r'http\\S+', \"\", text)\r\n",
                "    text = re.sub(\"#\", \"\", text)\r\n",
                "    text = re.sub(r'\\[removed\\]', \"\", text) # remove deleted comments\r\n",
                "    text = re.sub(r'\\[deleted\\]', \"\", text)\r\n",
                "    text = \"\".join([ch for ch in text if ch not in punct])\r\n",
                "    text = re.sub(r'[0-9]', \"\", text)\r\n",
                "    remove_comments.append(text)\r\n",
                "\"\"\""
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'\\nremove_comments = []\\nfor text in unicode_comments:\\n    text = re.sub(\"@\\\\S+\", \"\", text)\\n    text = re.sub(\"\\\\$\", \"\", text)\\n    text = re.sub(r\\'http\\\\S+\\', \"\", text)\\n    text = re.sub(\"#\", \"\", text)\\n    text = re.sub(r\\'\\\\[removed\\\\]\\', \"\", text) # remove deleted comments\\n    text = re.sub(r\\'\\\\[deleted\\\\]\\', \"\", text)\\n    text = \"\".join([ch for ch in text if ch not in punct])\\n    text = re.sub(r\\'[0-9]\\', \"\", text)\\n    remove_comments.append(text)\\n'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 8
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "# lemmatize\r\n",
                "import nltk\r\n",
                "from nltk.stem import WordNetLemmatizer\r\n",
                "lemmatizer = WordNetLemmatizer()\r\n",
                "\r\n",
                "lemma_title = []\r\n",
                "for text in remove_title:\r\n",
                "    lemmatized = [lemmatizer.lemmatize(word) for word in text.split()]\r\n",
                "    text = \" \".join(word for word in lemmatized)\r\n",
                "    lemma_title.append(text)\r\n",
                "lemma_body = []\r\n",
                "for text in remove_body:\r\n",
                "    lemmatized = [lemmatizer.lemmatize(word) for word in text.split()]\r\n",
                "    text = \" \".join(word for word in lemmatized)\r\n",
                "    lemma_body.append(text)\r\n",
                "\"\"\"\r\n",
                "lemma_comments = []\r\n",
                "for text in remove_comments:\r\n",
                "    lemmatized = [lemmatizer.lemmatize(word) for word in text.split()]\r\n",
                "    text = \" \".join(word for word in lemmatized)\r\n",
                "    lemma_comments.append(text)\r\n",
                "\"\"\""
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'\\nlemma_comments = []\\nfor text in remove_comments:\\n    lemmatized = [lemmatizer.lemmatize(word) for word in text.split()]\\n    text = \" \".join(word for word in lemmatized)\\n    lemma_comments.append(text)\\n'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 9
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "# word frequency list\r\n",
                "import pandas as pd\r\n",
                "import nltk\r\n",
                "pd.Series(' '.join(lemma_body).split()).value_counts()[:10]\r\n",
                "# word frequency list can suggest words that might be common but not useful - will need to take note in EDA"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "like      13342\n",
                            "would     11184\n",
                            "time       9528\n",
                            "get        8900\n",
                            "know       8595\n",
                            "really     8539\n",
                            "year       8061\n",
                            "people     7707\n",
                            "one        7592\n",
                            "even       7368\n",
                            "dtype: int64"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 10
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "print(len(lemma_title))\r\n",
                "data[\"clean_title\"] = lemma_title\r\n",
                "print(len(lemma_body))\r\n",
                "data[\"clean_selftext\"] = lemma_body\r\n",
                "\"\"\"\r\n",
                "print(len(lemma_comments))\r\n",
                "data[\"clean_comments\"] = lemma_comments\r\n",
                "\"\"\"\r\n",
                "data.head()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "21367\n",
                        "21367\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   Unnamed: 0          subreddit  subreddit_subscribers  \\\n",
                            "0           1          singapore                 378959   \n",
                            "1           2       askSingapore                  44675   \n",
                            "2           3          singapore                 378959   \n",
                            "3           4  NationalServiceSG                  11091   \n",
                            "4           5       askSingapore                  44675   \n",
                            "\n",
                            "                                               title      id  \\\n",
                            "0  About 71,600 in S'pore have psychotic disorder...  nhxjoa   \n",
                            "1  Anyone know where to get tested as an Adult fo...  ng6k8b   \n",
                            "2  'She didn't even have time to grieve': Some do...  ksalf9   \n",
                            "3                       Help for adjustment disorder  mfnwal   \n",
                            "4        Where to get assessed for eating disorders?  l0ac4u   \n",
                            "\n",
                            "              author created_utc  num_comments  score  \\\n",
                            "0  MicrotechAnalysis  2021-05-22            36    117   \n",
                            "1       summerfellxx  2021-05-19             6      8   \n",
                            "2           DrCalFun  2021-01-07            90    202   \n",
                            "3       ElijahThor00  2021-03-29             6      5   \n",
                            "4      kanicroquette  2021-01-19             9     42   \n",
                            "\n",
                            "                                            selftext  \\\n",
                            "0                                                NaN   \n",
                            "1  I know mostly these tests are for children. Bu...   \n",
                            "2                                                NaN   \n",
                            "3  People say half the war is won when you report...   \n",
                            "4  I might have an eating disorder, I don’t know ...   \n",
                            "\n",
                            "                                                 url  upvote_ratio  \\\n",
                            "0  https://www.straitstimes.com/singapore/health/...          0.96   \n",
                            "1  https://www.reddit.com/r/askSingapore/comments...          0.84   \n",
                            "2  https://www.asiaone.com/singapore/she-didnt-ev...          0.94   \n",
                            "3  https://www.reddit.com/r/NationalServiceSG/com...          0.86   \n",
                            "4  https://www.reddit.com/r/askSingapore/comments...          1.00   \n",
                            "\n",
                            "                                         clean_title  \\\n",
                            "0                 spore psychotic disorder say study   \n",
                            "1  anyone know get tested adult auditory processi...   \n",
                            "2  she even time grieve donor ask mum refund boy ...   \n",
                            "3                           help adjustment disorder   \n",
                            "4                       get assessed eating disorder   \n",
                            "\n",
                            "                                      clean_selftext  \n",
                            "0                                                     \n",
                            "1  know mostly test child really need know wrong ...  \n",
                            "2                                                     \n",
                            "3  people say half war report mental illness long...  \n",
                            "4  might eating disorder know want self diagnose ...  "
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Unnamed: 0</th>\n",
                            "      <th>subreddit</th>\n",
                            "      <th>subreddit_subscribers</th>\n",
                            "      <th>title</th>\n",
                            "      <th>id</th>\n",
                            "      <th>author</th>\n",
                            "      <th>created_utc</th>\n",
                            "      <th>num_comments</th>\n",
                            "      <th>score</th>\n",
                            "      <th>selftext</th>\n",
                            "      <th>url</th>\n",
                            "      <th>upvote_ratio</th>\n",
                            "      <th>clean_title</th>\n",
                            "      <th>clean_selftext</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>378959</td>\n",
                            "      <td>About 71,600 in S'pore have psychotic disorder...</td>\n",
                            "      <td>nhxjoa</td>\n",
                            "      <td>MicrotechAnalysis</td>\n",
                            "      <td>2021-05-22</td>\n",
                            "      <td>36</td>\n",
                            "      <td>117</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>https://www.straitstimes.com/singapore/health/...</td>\n",
                            "      <td>0.96</td>\n",
                            "      <td>spore psychotic disorder say study</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>askSingapore</td>\n",
                            "      <td>44675</td>\n",
                            "      <td>Anyone know where to get tested as an Adult fo...</td>\n",
                            "      <td>ng6k8b</td>\n",
                            "      <td>summerfellxx</td>\n",
                            "      <td>2021-05-19</td>\n",
                            "      <td>6</td>\n",
                            "      <td>8</td>\n",
                            "      <td>I know mostly these tests are for children. Bu...</td>\n",
                            "      <td>https://www.reddit.com/r/askSingapore/comments...</td>\n",
                            "      <td>0.84</td>\n",
                            "      <td>anyone know get tested adult auditory processi...</td>\n",
                            "      <td>know mostly test child really need know wrong ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>378959</td>\n",
                            "      <td>'She didn't even have time to grieve': Some do...</td>\n",
                            "      <td>ksalf9</td>\n",
                            "      <td>DrCalFun</td>\n",
                            "      <td>2021-01-07</td>\n",
                            "      <td>90</td>\n",
                            "      <td>202</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>https://www.asiaone.com/singapore/she-didnt-ev...</td>\n",
                            "      <td>0.94</td>\n",
                            "      <td>she even time grieve donor ask mum refund boy ...</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>NationalServiceSG</td>\n",
                            "      <td>11091</td>\n",
                            "      <td>Help for adjustment disorder</td>\n",
                            "      <td>mfnwal</td>\n",
                            "      <td>ElijahThor00</td>\n",
                            "      <td>2021-03-29</td>\n",
                            "      <td>6</td>\n",
                            "      <td>5</td>\n",
                            "      <td>People say half the war is won when you report...</td>\n",
                            "      <td>https://www.reddit.com/r/NationalServiceSG/com...</td>\n",
                            "      <td>0.86</td>\n",
                            "      <td>help adjustment disorder</td>\n",
                            "      <td>people say half war report mental illness long...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5</td>\n",
                            "      <td>askSingapore</td>\n",
                            "      <td>44675</td>\n",
                            "      <td>Where to get assessed for eating disorders?</td>\n",
                            "      <td>l0ac4u</td>\n",
                            "      <td>kanicroquette</td>\n",
                            "      <td>2021-01-19</td>\n",
                            "      <td>9</td>\n",
                            "      <td>42</td>\n",
                            "      <td>I might have an eating disorder, I don’t know ...</td>\n",
                            "      <td>https://www.reddit.com/r/askSingapore/comments...</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>get assessed eating disorder</td>\n",
                            "      <td>might eating disorder know want self diagnose ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 11
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "for col in data.columns:\r\n",
                "    print(col)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Unnamed: 0\n",
                        "subreddit\n",
                        "subreddit_subscribers\n",
                        "title\n",
                        "id\n",
                        "author\n",
                        "created_utc\n",
                        "num_comments\n",
                        "score\n",
                        "selftext\n",
                        "url\n",
                        "upvote_ratio\n",
                        "clean_title\n",
                        "clean_selftext\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "# filter for null author was done in cleaning.Rmd before, but it seems it is not done properly, so its repeated here\r\n",
                "# data originally has 21367 rows, after filter, we have 18317 rows\r\n",
                "data = data[data[\"author\"].notnull()]\r\n",
                "data"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "       Unnamed: 0          subreddit  subreddit_subscribers  \\\n",
                            "0               1          singapore                 378959   \n",
                            "1               2       askSingapore                  44675   \n",
                            "2               3          singapore                 378959   \n",
                            "3               4  NationalServiceSG                  11091   \n",
                            "4               5       askSingapore                  44675   \n",
                            "...           ...                ...                    ...   \n",
                            "21359       84051          singapore                 159359   \n",
                            "21361       84071          singapore                 158417   \n",
                            "21362       84081          singapore                 154905   \n",
                            "21363       84091          singapore                 167257   \n",
                            "21364       84101          singapore                 195542   \n",
                            "\n",
                            "                                                   title      id  \\\n",
                            "0      About 71,600 in S'pore have psychotic disorder...  nhxjoa   \n",
                            "1      Anyone know where to get tested as an Adult fo...  ng6k8b   \n",
                            "2      'She didn't even have time to grieve': Some do...  ksalf9   \n",
                            "3                           Help for adjustment disorder  mfnwal   \n",
                            "4            Where to get assessed for eating disorders?  l0ac4u   \n",
                            "...                                                  ...     ...   \n",
                            "21359                                  Influenza Vaccine  b0hzfi   \n",
                            "21361  Parliament: Free opt-in cervical cancer vaccin...  axxk5x   \n",
                            "21362  [ladies] HPV vaccination - y/n, experience, co...  ap5vn0   \n",
                            "21363  93% of Sec 1 girls opt for free cervical cance...  blzm57   \n",
                            "21364  Planning to go back to SG this December. Polio...  dopbox   \n",
                            "\n",
                            "                  author created_utc  num_comments  score  \\\n",
                            "0      MicrotechAnalysis  2021-05-22            36    117   \n",
                            "1           summerfellxx  2021-05-19             6      8   \n",
                            "2               DrCalFun  2021-01-07            90    202   \n",
                            "3           ElijahThor00  2021-03-29             6      5   \n",
                            "4          kanicroquette  2021-01-19             9     42   \n",
                            "...                  ...         ...           ...    ...   \n",
                            "21359         wintersoju  2019-03-13             8      7   \n",
                            "21361         dailyfield  2019-03-06            40    126   \n",
                            "21362          yummydubu  2019-02-10            20      1   \n",
                            "21363     Jammy_buttons2  2019-05-08            33    152   \n",
                            "21364  jasonrodriguez_DT  2019-10-29             6      0   \n",
                            "\n",
                            "                                                selftext  \\\n",
                            "0                                                    NaN   \n",
                            "1      I know mostly these tests are for children. Bu...   \n",
                            "2                                                    NaN   \n",
                            "3      People say half the war is won when you report...   \n",
                            "4      I might have an eating disorder, I don’t know ...   \n",
                            "...                                                  ...   \n",
                            "21359  Are there different brands of the vaccine avai...   \n",
                            "21361                                                NaN   \n",
                            "21362  Currently researching the vaccination and wond...   \n",
                            "21363                                                NaN   \n",
                            "21364  I checked a couple of sites including your Min...   \n",
                            "\n",
                            "                                                     url  upvote_ratio  \\\n",
                            "0      https://www.straitstimes.com/singapore/health/...          0.96   \n",
                            "1      https://www.reddit.com/r/askSingapore/comments...          0.84   \n",
                            "2      https://www.asiaone.com/singapore/she-didnt-ev...          0.94   \n",
                            "3      https://www.reddit.com/r/NationalServiceSG/com...          0.86   \n",
                            "4      https://www.reddit.com/r/askSingapore/comments...          1.00   \n",
                            "...                                                  ...           ...   \n",
                            "21359  https://www.reddit.com/r/singapore/comments/b0...          0.71   \n",
                            "21361  https://www.straitstimes.com/politics/parliame...          0.97   \n",
                            "21362  https://www.reddit.com/r/singapore/comments/ap...          0.73   \n",
                            "21363  https://www.straitstimes.com/singapore/93-of-s...          0.98   \n",
                            "21364  https://www.reddit.com/r/singapore/comments/do...          0.56   \n",
                            "\n",
                            "                                             clean_title  \\\n",
                            "0                     spore psychotic disorder say study   \n",
                            "1      anyone know get tested adult auditory processi...   \n",
                            "2      she even time grieve donor ask mum refund boy ...   \n",
                            "3                               help adjustment disorder   \n",
                            "4                           get assessed eating disorder   \n",
                            "...                                                  ...   \n",
                            "21359                                  influenza vaccine   \n",
                            "21361  parliament free optin cervical cancer vaccine ...   \n",
                            "21362  lady hpv vaccination yn experience cost medisa...   \n",
                            "21363     sec girl opt free cervical cancer vaccine khor   \n",
                            "21364  planning go back sg december polio vaccine req...   \n",
                            "\n",
                            "                                          clean_selftext  \n",
                            "0                                                         \n",
                            "1      know mostly test child really need know wrong ...  \n",
                            "2                                                         \n",
                            "3      people say half war report mental illness long...  \n",
                            "4      might eating disorder know want self diagnose ...  \n",
                            "...                                                  ...  \n",
                            "21359  different brand vaccine available difference g...  \n",
                            "21361                                                     \n",
                            "21362  currently researching vaccination wondering ma...  \n",
                            "21363                                                     \n",
                            "21364  checked couple site including ministry health ...  \n",
                            "\n",
                            "[18317 rows x 14 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Unnamed: 0</th>\n",
                            "      <th>subreddit</th>\n",
                            "      <th>subreddit_subscribers</th>\n",
                            "      <th>title</th>\n",
                            "      <th>id</th>\n",
                            "      <th>author</th>\n",
                            "      <th>created_utc</th>\n",
                            "      <th>num_comments</th>\n",
                            "      <th>score</th>\n",
                            "      <th>selftext</th>\n",
                            "      <th>url</th>\n",
                            "      <th>upvote_ratio</th>\n",
                            "      <th>clean_title</th>\n",
                            "      <th>clean_selftext</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>378959</td>\n",
                            "      <td>About 71,600 in S'pore have psychotic disorder...</td>\n",
                            "      <td>nhxjoa</td>\n",
                            "      <td>MicrotechAnalysis</td>\n",
                            "      <td>2021-05-22</td>\n",
                            "      <td>36</td>\n",
                            "      <td>117</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>https://www.straitstimes.com/singapore/health/...</td>\n",
                            "      <td>0.96</td>\n",
                            "      <td>spore psychotic disorder say study</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2</td>\n",
                            "      <td>askSingapore</td>\n",
                            "      <td>44675</td>\n",
                            "      <td>Anyone know where to get tested as an Adult fo...</td>\n",
                            "      <td>ng6k8b</td>\n",
                            "      <td>summerfellxx</td>\n",
                            "      <td>2021-05-19</td>\n",
                            "      <td>6</td>\n",
                            "      <td>8</td>\n",
                            "      <td>I know mostly these tests are for children. Bu...</td>\n",
                            "      <td>https://www.reddit.com/r/askSingapore/comments...</td>\n",
                            "      <td>0.84</td>\n",
                            "      <td>anyone know get tested adult auditory processi...</td>\n",
                            "      <td>know mostly test child really need know wrong ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>378959</td>\n",
                            "      <td>'She didn't even have time to grieve': Some do...</td>\n",
                            "      <td>ksalf9</td>\n",
                            "      <td>DrCalFun</td>\n",
                            "      <td>2021-01-07</td>\n",
                            "      <td>90</td>\n",
                            "      <td>202</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>https://www.asiaone.com/singapore/she-didnt-ev...</td>\n",
                            "      <td>0.94</td>\n",
                            "      <td>she even time grieve donor ask mum refund boy ...</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>NationalServiceSG</td>\n",
                            "      <td>11091</td>\n",
                            "      <td>Help for adjustment disorder</td>\n",
                            "      <td>mfnwal</td>\n",
                            "      <td>ElijahThor00</td>\n",
                            "      <td>2021-03-29</td>\n",
                            "      <td>6</td>\n",
                            "      <td>5</td>\n",
                            "      <td>People say half the war is won when you report...</td>\n",
                            "      <td>https://www.reddit.com/r/NationalServiceSG/com...</td>\n",
                            "      <td>0.86</td>\n",
                            "      <td>help adjustment disorder</td>\n",
                            "      <td>people say half war report mental illness long...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>5</td>\n",
                            "      <td>askSingapore</td>\n",
                            "      <td>44675</td>\n",
                            "      <td>Where to get assessed for eating disorders?</td>\n",
                            "      <td>l0ac4u</td>\n",
                            "      <td>kanicroquette</td>\n",
                            "      <td>2021-01-19</td>\n",
                            "      <td>9</td>\n",
                            "      <td>42</td>\n",
                            "      <td>I might have an eating disorder, I don’t know ...</td>\n",
                            "      <td>https://www.reddit.com/r/askSingapore/comments...</td>\n",
                            "      <td>1.00</td>\n",
                            "      <td>get assessed eating disorder</td>\n",
                            "      <td>might eating disorder know want self diagnose ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21359</th>\n",
                            "      <td>84051</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>159359</td>\n",
                            "      <td>Influenza Vaccine</td>\n",
                            "      <td>b0hzfi</td>\n",
                            "      <td>wintersoju</td>\n",
                            "      <td>2019-03-13</td>\n",
                            "      <td>8</td>\n",
                            "      <td>7</td>\n",
                            "      <td>Are there different brands of the vaccine avai...</td>\n",
                            "      <td>https://www.reddit.com/r/singapore/comments/b0...</td>\n",
                            "      <td>0.71</td>\n",
                            "      <td>influenza vaccine</td>\n",
                            "      <td>different brand vaccine available difference g...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21361</th>\n",
                            "      <td>84071</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>158417</td>\n",
                            "      <td>Parliament: Free opt-in cervical cancer vaccin...</td>\n",
                            "      <td>axxk5x</td>\n",
                            "      <td>dailyfield</td>\n",
                            "      <td>2019-03-06</td>\n",
                            "      <td>40</td>\n",
                            "      <td>126</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>https://www.straitstimes.com/politics/parliame...</td>\n",
                            "      <td>0.97</td>\n",
                            "      <td>parliament free optin cervical cancer vaccine ...</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21362</th>\n",
                            "      <td>84081</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>154905</td>\n",
                            "      <td>[ladies] HPV vaccination - y/n, experience, co...</td>\n",
                            "      <td>ap5vn0</td>\n",
                            "      <td>yummydubu</td>\n",
                            "      <td>2019-02-10</td>\n",
                            "      <td>20</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Currently researching the vaccination and wond...</td>\n",
                            "      <td>https://www.reddit.com/r/singapore/comments/ap...</td>\n",
                            "      <td>0.73</td>\n",
                            "      <td>lady hpv vaccination yn experience cost medisa...</td>\n",
                            "      <td>currently researching vaccination wondering ma...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21363</th>\n",
                            "      <td>84091</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>167257</td>\n",
                            "      <td>93% of Sec 1 girls opt for free cervical cance...</td>\n",
                            "      <td>blzm57</td>\n",
                            "      <td>Jammy_buttons2</td>\n",
                            "      <td>2019-05-08</td>\n",
                            "      <td>33</td>\n",
                            "      <td>152</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>https://www.straitstimes.com/singapore/93-of-s...</td>\n",
                            "      <td>0.98</td>\n",
                            "      <td>sec girl opt free cervical cancer vaccine khor</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21364</th>\n",
                            "      <td>84101</td>\n",
                            "      <td>singapore</td>\n",
                            "      <td>195542</td>\n",
                            "      <td>Planning to go back to SG this December. Polio...</td>\n",
                            "      <td>dopbox</td>\n",
                            "      <td>jasonrodriguez_DT</td>\n",
                            "      <td>2019-10-29</td>\n",
                            "      <td>6</td>\n",
                            "      <td>0</td>\n",
                            "      <td>I checked a couple of sites including your Min...</td>\n",
                            "      <td>https://www.reddit.com/r/singapore/comments/do...</td>\n",
                            "      <td>0.56</td>\n",
                            "      <td>planning go back sg december polio vaccine req...</td>\n",
                            "      <td>checked couple site including ministry health ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>18317 rows × 14 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "data.to_csv(r\"C:\\\\Users\\\\20jam\\\\Documents\\\\GitHub\\\\omdena-singapore-covid-health\\\\src\\\\data\\\\reddit\\\\fulldata_clean.csv\", index = False, header = True)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.4",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.4 64-bit"
        },
        "interpreter": {
            "hash": "bf3e9a0eaed196172b25c3c8d2e3c0605dffe77010244cc0729cd883a8cd1a4e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}